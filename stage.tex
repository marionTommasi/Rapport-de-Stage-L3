\section{Stage}

\subsection{But}
%expliquer le sujet / les idées de départ :
%      	trier la kbwt (améliorer la compression)
%		garder les propriétés de la bwt
%		améliorer l'indexation (éviter les calculs redondants)
Le but de ce travail est de proposer un algorithme efficace de compression et d'indexation des reads peu gourmand en mémoire. Pour cela, la piste privilégiée est l'étude de la transformée de Burrows-Wheeler à contexte borné. 

Les reads étant une donnée très redondante, la recherche d'un motif dans le texte devrait occasionner de nombreux calculs identiques. L'un des objectifs est donc d'optimiser la recherche en factorisant ces calculs. 

De plus, du fait de la redondance des données, les $k$-contextes devraient être grands et nombreux. Aussi, pour accentuer la probabilité d'obtenir de longues suites de caractères identiques, l'idée est de trier la \kbwt\ sur ses $k$-contextes, comme dans la figure \ref{tri}.

\begin{figure}[h!]
\fbox{%
  \begin{minipage}{\linewidth}
    t = "\textsc{aaacaaaacaaaaacaaa\$}"
  	\begin{center}
  	  \textsc{%
    00\quad \$an anaaanaana {\color{lightgray}a} a\\
    01\quad a\$a nanaaanaan {\color{lightgray}a} a\\
	02\quad aa\$ ananaaanaa {\color{lightgray}n} n\\
	03\quad aaa naanaa\$ana {\color{lightgray}n} n\\
	04\quad {\color{red}aan} aanaa\$anan {\color{lightgray}a} a\\
	05\quad {\color{red}aan} aa\$ananaaa {\color{lightgray}n} a\\
	06\quad {\color{blue}ana} naaanaanaa {\color{lightgray}\$} \$\\
	07\quad {\color{blue}ana} aanaanaa\$a {\color{lightgray}n} a\\
	08\quad {\color{blue}ana} anaa\$anana {\color{lightgray}a} a\\
	09\quad {\color{blue}ana} a\$ananaaan {\color{lightgray}a} n\\
	10\quad {\color{green}naa} anaanaa\$an {\color{lightgray}a} a\\
	11\quad {\color{green}naa} naa\$ananaa {\color{lightgray}a} a\\
	12\quad {\color{green}naa} \$ananaaana {\color{lightgray}a} a\\
	13\quad nan aaanaanaa\$ {\color{lightgray}a} a
	  }
	\end{center}
	$k = 3$\\
	\kbwt(t) = "\textsc{aannaa\$naaaaaa}"\\
	\kbwt\ triée(t) = "\textsc{aannaa\$aanaaaa}"
  \end{minipage}%
}
\caption{Les $k$-contextes ont été colorés. On peut voir sur le $k$-contexte bleu la différence entre la \kbwt\ (en gris), et la \kbwt\ triée (à droite en noir).}
\label{tri}
\end{figure}

Il faut donc fournir les structures et algorithmes nécessaires au maintien des propriétés de la \bwt\ sur la \kbwt\ triée.


\subsection{Approche}
%	implémentation de la bwt, kbwt, kbwt triée
%	étude sur l'entropie des différentes structures
%	essai de compression avec différents compresseurs existants
%	stocker LF plutot que les structures de Petri
%	optimiser le stockage de LF
%	enlever les k-contextes chevauchant 2 reads
\subsubsection{Tri dans les k-contextes}
Pour pouvoir trier la \kbwt, il faut s'assurer qu'il est possible de l'inverser, et garder l'indexation.

Il n'est pas possible d'inverser la \kbwt\ triée telle quelle, puisqu'il est impossible de savoir dans quel ordre étaient les $k$-contextes avant qu'il ne soient triés. Par exemple, \textsc{"ana\textbf{na}anaaanaa\$"} et \textsc{"ana\textbf{an}anaaanaa\$"} ont la même \kbwt\ triée.

Il faut donc conserver des informations supplémentaires pour pouvoir retrouver l'ordre original.

Une idée simple est de conserver les permutations pendant le tri des $k$-contextes. Un simple tableau d'entiers, cependant, prend beaucoup de place.

L'idée est donc de stocker la \kbwt\ dans un wavelett tree, et de garder un vecteur de bit pour mémoriser les changements. Ainsi, le vecteur mappe bit à bit la le wavelett tree de la \kbwt, et est placé à 1 si le bit du wavelett tree change entre la \kbwt\ et la \kbwt\ triée. Ainsi, le passage de la \kbwt\ à celle triée, et inversement, se fait grâce à un \textit{ou exclusif} ($xor$) avec le vecteur de bit.

Le vecteur de bit obtenu ne devrait contenir que très peu de 1. Les \textit{sarray} de Okanohara et Sakadane\up{\cite{sarray}} sont optimisés pour les vecteurs de bits éparses. L'information des permutations ne devrait donc pas prendre beaucoup de place.

\subsubsection{Redondance des calculs}
Pour la redondance des calculs, la première idée a été de calculer la position des motifs par blocs. Nous nous intéresserons ici qu'aux motifs de taille inférieure ou égale à $k$. 

Tout d'abord, on utilise la \textit{backward search} de Ferragina et Manzini pour déterminer à quel endroit de la \kbwt\ se trouve le motif, et on calcul le nombre de rotations concernées. Il faut maintenant retrouver sa position dans le texte, ce qui se fait grâce à la fonction LF() pour les rotations n'étant pas dans le tableau de suffixe. Or, nous travaillons ici sur des reads, donnée très redondante. La plupart des motifs trouvés ont une forte probabilité de faire partie d'un même motif commun plus grand. Par exemple, dans \textsc{barbapapa\$}, les motifs \textsc{pa} font tous les deux partie du motif \textsc{apa}. La conséquence, comme illustrée dans la figure \ref{redondant} est que la fonction LF() appliquée sur chaque motif nous renverra dans une zone commune de la \kbwt, avec les mêmes motifs les uns à côté des autres. C'est pour cela que l'on propose de calculer LF() par \textit{blocs}, c'est-à-dire de calculer LF() pour la première et la dernière rotation dont le motif recherché est préfixe, et d'inférer grâce à celles-là les autres.




%
%Premières idées :
%	. chercher par blocs (-> seulement quand bloc assez grand)
%	. stocker permutations (-> infos ne peut pas se contenir elle meme ; décrire différentes idées stockage)
%Implémentation pour tester faisabilité
%étude de la compression
%calcul de l'entropie pour voir si correspond
%compression avec compresseurs existants
%
%pour recherche, besoin de lf. pour lf besoin struc Petri -> lourd
%sur k-contextes, lf croissante -> stocker lf ? mieux
%
%lf lourde
%essais compression
%
%petits k-contextes qd \$ dans contexte -> enlever ces contextes ?
%non

\subsection{Résultats} 

expliquer les stuctures et algos les plus efficaces et donner les temps d'accès et taux de compression.
